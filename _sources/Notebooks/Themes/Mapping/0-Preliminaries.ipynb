{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "present-quarterly",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "We need to download some data for the examples. Some files are bundled with the notebooks because I am not smart enough to understand how to download them through the various web / ftp interfaces directly or I needed to filter or compress the information for the purposes of the class. Please go to the original sites if you need to use these data for anything other than the demonstrations in these notebooks.\n",
    "\n",
    "Most datasets are too large for the repository (and generally, that's not a place to keep anything which is not the primary target of revision management. The bundled data are compressed and will be unpacked (copied) to the `../../Data/Resources` directory by the \"download\" functions in this notebook. If you mess them up, just run the download again. Anything that is undamaged will just be be skipped anyway.\n",
    "\n",
    "## Global Magnetic Data\n",
    "\n",
    "Magnetic intensity data from [geomag.org](http://geomag.org/models/EMAG2/EMAG2_V2.tif)\n",
    "\n",
    "## Topography data\n",
    "\n",
    "ETOPO1 images are from NOAA - we use their geotifs which are subsampled from the original (enormous) dataset but \n",
    "\n",
    "## NASA Blue marble images\n",
    "\n",
    "Winter and Summer images for the Earth are grabbed for plotting examples. The winter ones (June) are used by default as these have less ice in the N. Hemisphere. \n",
    "\n",
    "## Earthquake hypocentres\n",
    "\n",
    "Are grabbed from the [NEIC](http://earthquake.usgs.gov/earthquakes/search/) - they are in the geoJSON format since that is very simple to read with python. The downloads are limited at 20k events so the time and magnitude range is whatever it takes to get just under this limit. The filenames give clues about that, but, so does the catalogue itself once it is read in.\n",
    "\n",
    "## Global age grid \n",
    "\n",
    "Taken from Earthbyte and reduced in size by throwing away the grid information and saving in compressed numpy format. \n",
    "\n",
    "## Global strain rate\n",
    "\n",
    "I grabbed the second invariant of the strain rate from the [global strain rate map](http://gsrm.unavco.org/intro) project through the 'Jules Vernes' portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overall-lodge",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw-r--r-- 1 runner docker 181 Mar 22 11:52 README.md\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ls -l Resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-nylon",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "## The datasets that we use for this course are kept in a central location. \n",
    "\n",
    "These can be downloaded on demand from the cloudstor service which is provided by AARNET.\n",
    "Anyone with an Australian university affiliation can ask for substantial storage on cloudstor\n",
    "and it is a fast, reliable service.\n",
    "\n",
    "   - Why do I do that ? \n",
    "\n",
    "So if you happen to delete or break one of the datasets, we can just get a new copy. Also,\n",
    "these kinds of data are not allowed on revision control sites like Github because they are \n",
    "large binary files and break the notion of revision control. \n",
    "\n",
    "There is a python module `cloudstor` that can grab data anonymously from read-only folders.\n",
    "\n",
    "``` python\n",
    "\n",
    "from cloudstor import cloudstor\n",
    "\n",
    "teaching_data = cloudstor(url=\"L93TxcmtLQzcfbk\", password='')\n",
    "teaching_data.list()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innocent-engineering",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cloudstor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-45cc18c6d409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcloudstor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcloudstor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mteaching_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudstor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L93TxcmtLQzcfbk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mteaching_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cloudstor'"
     ]
    }
   ],
   "source": [
    "from cloudstor import cloudstor\n",
    "\n",
    "teaching_data = cloudstor(url=\"L93TxcmtLQzcfbk\", password='')\n",
    "teaching_data.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "involved-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AusMagAll.tiff to Resources directory\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'teaching_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-73eda96363a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resources/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading {} to Resources directory\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mteaching_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resources\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'teaching_data' is not defined"
     ]
    }
   ],
   "source": [
    "download_list = [\n",
    " 'AusMagAll.tiff',\n",
    " 'BlueMarbleNG-TB_2004-12-01_rgb_3600x1800.TIFF',\n",
    " 'EMAG2_image_V2_Small.tif',\n",
    " 'EMAG2_image_V2_no_compr.tif',\n",
    " 'ETOPO1_Ice_c_geotiff.tif',\n",
    " 'Etopo1_3600x1800.tif',\n",
    " 'color_etopo1_ice_low.tif',\n",
    " 'etopo1_grayscale_hillshade.tif',\n",
    " 'etopo1_grayscale_hillshade_small.tif',\n",
    " 'events_4.5+by_year_1970-2019.npy',\n",
    " 'global_age_data.3.6.z.npz',\n",
    " 'sec_invariant_strain_0.2.dat',\n",
    " 'velocity_AU.nc',\n",
    " 'velocity_EU.nc',\n",
    " 'velocity_IN.nc',\n",
    " 'velocity_NA.nc',\n",
    " 'velocity_NNR.nc',\n",
    " 'velocity_OK.nc',\n",
    " 'velocity_PA.nc'\n",
    "]\n",
    "\n",
    "for file in download_list:\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    # Check if it exists already (should check to see if it is the correct file ... compare checksum)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(\"Resources/\",file)):\n",
    "        print(\"Downloading {} to Resources directory\".format(file))\n",
    "        teaching_data.download_file(file, os.path.join(\"Resources\",file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-madrid",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teaching_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e24874bf3af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This is how we download a whole directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mteaching_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EQs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Resources/EQs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mteaching_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HYP_50M_SR_W\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Resources/HYP_50M_SR_W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mteaching_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OB_50M\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Resources/OB_50M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'teaching_data' is not defined"
     ]
    }
   ],
   "source": [
    "# This is how we download a whole directory\n",
    "\n",
    "teaching_data.download_directory(\"EQs\",\"Resources/EQs\")\n",
    "teaching_data.download_directory(\"HYP_50M_SR_W\",\"Resources/HYP_50M_SR_W\")\n",
    "teaching_data.download_directory(\"OB_50M\",\"Resources/OB_50M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mental-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract any files that were downloaded as zip archives (keep the originals to avoid re-downloading)\n",
    "\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "for zipped in glob.glob(\"../../Data/Resources/*.zip\"):\n",
    "    with zipfile.ZipFile(zipped) as zf:\n",
    "        zf.extractall(\"../../Data/Resources\")\n",
    "        print (\"Unzipped {}\".format(zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-giant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "source_map": [
   12,
   44,
   52,
   77,
   84,
   118,
   126,
   138
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}